{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate MEMIT results from validation runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY THE VALIDATION SWEEP LOG DIRECTORY HERE\n",
    "result_dir = 'log_memit_101023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test script generation params\n",
    "make_test_scripts = True\n",
    "num_trials = 5\n",
    "out_log_dir = 'log_memit_101023_test_results' # dir to write results into\n",
    "sweep_script_dir = 'sbatches_101023' # dir to write script logs into\n",
    "sweep_script_write_dir = 'sbatches_101023/test_scripts' # dir to write scripts into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAGUES = [0.001, 0.0001, 0.00001]\n",
    "dnames = [\n",
    "    'company', \n",
    "    'country', \n",
    "    'verbs', \n",
    "    'temporal', \n",
    "    'stereoset', \n",
    "    'gender'    \n",
    "]\n",
    "model_names = [\n",
    "    # 'backpack-gpt2',\n",
    "    'pythia-70m',\n",
    "    'pythia-160m',\n",
    "    'pythia-410m',\n",
    "    'pythia-1b',\n",
    "    'pythia-1.4b',\n",
    "    'pythia-2.8b',\n",
    "    'pythia-6.9b'\n",
    "]\n",
    "subject_types = ['true_subject', 'prefix_subject']\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for st in subject_types:\n",
    "    results_dict[st] = {}\n",
    "    for m in model_names:\n",
    "        results_dict[st][m] = {}\n",
    "        for d in dnames:\n",
    "            results_dict[st][m][d] = {}\n",
    "for root, _, files in os.walk(result_dir):\n",
    "    for fname in files:\n",
    "        if 'noedit' in fname:\n",
    "            continue # skip no-edit \n",
    "\n",
    "        param_keys = ['model', 'dataset', 'layers', 'v_num_grad_steps', 'clamp_norm_factor', \n",
    "                  'mom2_update_weight', 'kl_factor']\n",
    "        param_dict = dict(zip(param_keys, fname[:-5].split('__')))\n",
    "\n",
    "        param_str = '__'.join(param_dict[x] for x in param_keys[4:])\n",
    "        dname = param_dict['dataset'].split('-')[0]\n",
    "        subject_type = param_dict['dataset'].split('-')[1]\n",
    "        results_dict[subject_type][param_dict['model']][dname][param_str] = json.load(open(os.path.join(root, fname), 'r'))\n",
    "\n",
    "# make sure there are 10 trials per model and dataset\n",
    "for mname in model_names:\n",
    "    for d in dnames:\n",
    "        assert len(results_dict['true_subject'][mname][d].keys()) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model_names:\n",
    "    for d in dnames:\n",
    "        for param_str in results_dict['prefix_subject'][m][d].keys():\n",
    "            assert results_dict['prefix_subject'][m][d][param_str]['noedit']['general_score'] == \\\n",
    "                results_dict['true_subject'][m][d][param_str]['noedit']['general_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether results fall in each league\n",
    "for st in subject_types:\n",
    "    for m in model_names:\n",
    "        for d in dnames:\n",
    "            for param_str in results_dict[st][m][d].keys():\n",
    "                data = results_dict[st][m][d][param_str] \n",
    "\n",
    "                for league in LEAGUES:\n",
    "                    league_loss_cutoff = data['noedit']['general_score']*(1+league)\n",
    "                    data['edit']['in_league_{}'.format(league)] = data['edit']['general_score'] < league_loss_cutoff\n",
    "                data['edit']['intervention_score_delta'] = data['edit']['intervention_score'] - data['noedit']['intervention_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best_config for each league\n",
    "best_configs = {}\n",
    "for m in model_names:\n",
    "    best_configs[m] = {}\n",
    "    for d in dnames:\n",
    "        for st in subject_types:\n",
    "            full_dname = '{}-{}'.format(d, st)\n",
    "            best_configs[m][full_dname] = {}\n",
    "best_results = {}\n",
    "for st in subject_types:\n",
    "    best_results[st] = {}\n",
    "    for m in model_names:\n",
    "        best_results[st][m] = {}\n",
    "        for d in dnames:\n",
    "            best_results[st][m][d] = {}\n",
    "\n",
    "for st in subject_types:\n",
    "    for m in model_names:\n",
    "        for d in dnames:\n",
    "            full_dname = '{}-{}'.format(d, st)\n",
    "            for league in LEAGUES:\n",
    "                # find the best config for each league\n",
    "\n",
    "                # find the runs in each league\n",
    "                options = []\n",
    "                for param_str in results_dict[st][m][d].keys():\n",
    "                    data = results_dict[st][m][d][param_str] \n",
    "                    if data['edit']['in_league_{}'.format(league)]:\n",
    "                        options.append(data)\n",
    "                # find the best run\n",
    "                lowest_intervention_score_delta = float('inf')\n",
    "                best_config = None \n",
    "                best_data = None\n",
    "                for data in options:\n",
    "                    if data['edit']['intervention_score_delta'] < lowest_intervention_score_delta:\n",
    "                        lowest_intervention_score_delta = data['edit']['intervention_score_delta']\n",
    "                        best_config = data['edit']['override_params']\n",
    "                        best_data = data\n",
    "\n",
    "                best_configs[m][full_dname][league] = best_config\n",
    "                best_results[st][m][d][league] = best_data\n",
    "\n",
    "                score_deltas = [data['edit']['intervention_score_delta'] for data in options]\n",
    "                if len(options) == 0:\n",
    "                    continue \n",
    "                best_index = score_deltas.index(min(score_deltas))\n",
    "\n",
    "                scores = [data['edit']['intervention_score'] for data in options]\n",
    "                best_score_index = scores.index(min(scores))\n",
    "                assert best_score_index == best_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename keys\n",
    "best_results['oracle'] = best_results['true_subject']\n",
    "best_results['prefix'] = best_results['prefix_subject']\n",
    "del best_results['true_subject']\n",
    "del best_results['prefix_subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.43942992874109266, -0.2114014251781473, -0.154394299287411]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[best_results['oracle'][mname][dname][l]['edit']['intervention_score_delta'] for l in LEAGUES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'intervention_score': 0.7375,\n",
       "  'general_score': 2.4101945486885255,\n",
       "  'rest_of_prompt_score': 4.347651209677419,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.07196986295533628,\n",
       "   'mom2_update_weight': 67872,\n",
       "   'kl_factor': 0.05166268048920571},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.078125},\n",
       " {'intervention_score': 0.55,\n",
       "  'general_score': 2.4102419003627404,\n",
       "  'rest_of_prompt_score': 4.346759072580645,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.1606518378829931,\n",
       "   'mom2_update_weight': 70141,\n",
       "   'kl_factor': 0.014489644151607108},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.265625},\n",
       " {'intervention_score': 0.66875,\n",
       "  'general_score': 2.4102418586799286,\n",
       "  'rest_of_prompt_score': 4.348933971774193,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.10724643357820046,\n",
       "   'mom2_update_weight': 50841,\n",
       "   'kl_factor': 0.05313765575910803},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.1468750000000001},\n",
       " {'intervention_score': 0.659375,\n",
       "  'general_score': 2.410236314865958,\n",
       "  'rest_of_prompt_score': 4.347764616935484,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.053378396260240116,\n",
       "   'mom2_update_weight': 17699,\n",
       "   'kl_factor': 0.040453137697182236},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.15625},\n",
       " {'intervention_score': 0.70625,\n",
       "  'general_score': 2.410237815447183,\n",
       "  'rest_of_prompt_score': 4.345017641129032,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.1040558278141125,\n",
       "   'mom2_update_weight': 66465,\n",
       "   'kl_factor': 0.017674030522754885},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.109375},\n",
       " {'intervention_score': 0.603125,\n",
       "  'general_score': 2.4102733708856565,\n",
       "  'rest_of_prompt_score': 4.335597278225807,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.2850050359463888,\n",
       "   'mom2_update_weight': 25502,\n",
       "   'kl_factor': 0.055353460422046676},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.21250000000000002},\n",
       " {'intervention_score': 0.578125,\n",
       "  'general_score': 2.410271495159125,\n",
       "  'rest_of_prompt_score': 4.340504032258065,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.3657366293916082,\n",
       "   'mom2_update_weight': 31443,\n",
       "   'kl_factor': 0.05548350519905669},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.23750000000000004},\n",
       " {'intervention_score': 0.490625,\n",
       "  'general_score': 2.4102515290922684,\n",
       "  'rest_of_prompt_score': 4.345176411290322,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.21581458404365803,\n",
       "   'mom2_update_weight': 69788,\n",
       "   'kl_factor': 0.03596454005817598},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.32500000000000007},\n",
       " {'intervention_score': 0.553125,\n",
       "  'general_score': 2.4102283534489026,\n",
       "  'rest_of_prompt_score': 4.34765372983871,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.23972648900449214,\n",
       "   'mom2_update_weight': 30876,\n",
       "   'kl_factor': 0.05672266946711038},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.26250000000000007},\n",
       " {'intervention_score': 0.66875,\n",
       "  'general_score': 2.4102107633023193,\n",
       "  'rest_of_prompt_score': 4.350713205645161,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.12236287486716506,\n",
       "   'mom2_update_weight': 71341,\n",
       "   'kl_factor': 0.03205034771645751},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': True,\n",
       "  'intervention_score_delta': -0.1468750000000001}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at results for a specific model and dataset\n",
    "st = 'true_subject'\n",
    "mname = 'pythia-6.9b'\n",
    "dname = 'gender'\n",
    "[x['edit'] for x in results_dict[st][mname][dname].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_results.val.final.float16.json\", \"w\") as fh:\n",
    "    json.dump(best_results, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make test scripts (using best val config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_sweep import get_sbatch_header, model_name_to_short, model_name_to_full\n",
    "\n",
    "\n",
    "def model_to_queue(model_name):\n",
    "    if '410m' in model_name or '160m' in model_name or '70m' in model_name or 'backpack' in model_name:\n",
    "        return 'jag-standard'\n",
    "    else:\n",
    "        return 'jag-lo'\n",
    "    \n",
    "def model_to_jags(model_name):\n",
    "    if '6.9b' in model_name or '2.8b' in model_name or '1.4b' in model_name or '1b' in model_name \\\n",
    "        or 'gpt-j' in model_name:\n",
    "        return ['jagupard37', 'jagupard38', 'jagupard39']\n",
    "    elif '410m' in model_name or '160m' in model_name or '70m' in model_name or 'backpack' in model_name:\n",
    "        return ['jagupard32', 'jagupard33', 'jagupard34', 'jagupard35', 'jagupard36']\n",
    "    else:\n",
    "        raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make scripts for the run on the test data\n",
    "\n",
    "if make_test_scripts:\n",
    "    machine_choosing_index = 0\n",
    "\n",
    "    dname_cfg_map = {\n",
    "        'company': 'company_ceo', 'country': 'country_capital', 'verbs': 'verb_conjugation', \n",
    "        'temporal': 'temporal', 'stereoset': 'stereoset', 'gender': 'pronoun_gender_bias'\n",
    "    }\n",
    "    run_cmds = []\n",
    "    filenames = []\n",
    "    for model_name in best_configs:\n",
    "        for full_dname in best_configs[model_name]:\n",
    "            for league in best_configs[model_name][full_dname]:\n",
    "                cur_config = best_configs[model_name][full_dname][league]\n",
    "                if cur_config is None:\n",
    "                    print(\">> WARNING: NO CONFIG YIELDED FOR\", model_name, full_dname, league)\n",
    "                    continue\n",
    "                dname, subject_type = full_dname.split('-')\n",
    "\n",
    "\n",
    "                short_model_name = model_name_to_short(model_name)\n",
    "                jag_options = model_to_jags(model_name)\n",
    "                nodelist = jag_options[machine_choosing_index % len(jag_options)]\n",
    "                machine_choosing_index += 1 \n",
    "\n",
    "\n",
    "                with open(f\"{sweep_script_write_dir}/{short_model_name}_{full_dname}_{league}.sbatch\", \"w\") as fh:\n",
    "                    filenames.append(f\"{sweep_script_write_dir}/{short_model_name}_{full_dname}_{league}.sbatch\")\n",
    "\n",
    "                    print(\n",
    "                        get_sbatch_header(\n",
    "                            run_name=f'{short_model_name}_{dname[:3]}_{league}_test-sweep', \n",
    "                            partition=model_to_queue(model_name), \n",
    "                            nodelist=nodelist,\n",
    "                            log_output_dir=f\"{sweep_script_dir}/test_logs\",\n",
    "                            num_hrs=12,\n",
    "                        ),\n",
    "                        file=fh\n",
    "                    )\n",
    "\n",
    "                    for t in range(num_trials):\n",
    "                        test_command = (\n",
    "                            f'python3 run_memit.py \"{model_name_to_full[model_name]}\" --v_num_grad_steps 20 '\n",
    "                            f'--clamp_norm_factor {cur_config[\"clamp_norm_factor\"]} '\n",
    "                            f'--mom2_update_weight {cur_config[\"mom2_update_weight\"]} '\n",
    "                            f'--kl_factor {cur_config[\"kl_factor\"]} '\n",
    "                            f'--dataset_names {dname} '\n",
    "                            f'--subject_types {subject_type} '\n",
    "                            f'--log_dir {out_log_dir} --test_mode '\n",
    "                            f'--override_exp_name {short_model_name}__{full_dname}__{league}__trial{t} '\n",
    "                            f'--seed {t}')\n",
    "\n",
    "                        run_cmd = (\n",
    "                            f\"{test_command} >> {sweep_script_dir}/test_logs/log.{short_model_name}_{full_dname}_{league}_{t}.txt\"\n",
    "                        )\n",
    "                        # run_cmd = (\n",
    "                        #     f\"srun --unbuffered run_as_child_processes '{test_command}' \"\n",
    "                        #     f\">> {sweep_script_dir}/test_logs/log.{model_name}_{full_dname}_{league}_{t}.txt\"\n",
    "                        # )                    \n",
    "                        print(run_cmd, file=fh)\n",
    "                        run_cmds.append(run_cmd)\n",
    "\n",
    "\n",
    "    for x in filenames:\n",
    "        print('sbatch', x)\n",
    "    print(len(filenames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backpacks-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
