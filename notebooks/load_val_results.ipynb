{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated MEMIT result agg (10-07-23 run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'log_memit_101023'\n",
    "# result_dir = 'log_memit_100723'\n",
    "\n",
    "LEAGUES = [0.001, 0.0001, 0.00001]\n",
    "dnames = [\n",
    "    'company', \n",
    "    'country', \n",
    "    'verbs', \n",
    "    'temporal', \n",
    "    'stereoset', \n",
    "    'gender'    \n",
    "]\n",
    "model_names = [\n",
    "    'backpack-gpt2',\n",
    "    'pythia-70m',\n",
    "    'pythia-160m',\n",
    "    'pythia-410m',\n",
    "    'pythia-1b',\n",
    "    'pythia-1.4b',\n",
    "    'pythia-2.8b',\n",
    "    'pythia-6.9b'\n",
    "]\n",
    "subject_types = [\n",
    "    'true_subject', 'prefix_subject'\n",
    "]\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for st in subject_types:\n",
    "    results_dict[st] = {}\n",
    "    for m in model_names:\n",
    "        results_dict[st][m] = {}\n",
    "        for d in dnames:\n",
    "            results_dict[st][m][d] = {}\n",
    "for root, _, files in os.walk(result_dir):\n",
    "    for fname in files:\n",
    "        if 'noedit' in fname:\n",
    "            continue # skip no-edit \n",
    "        # print(fname)\n",
    "        param_keys = ['model', 'dataset', 'layers', 'v_num_grad_steps', 'clamp_norm_factor', \n",
    "                  'mom2_update_weight', 'kl_factor']\n",
    "        param_dict = dict(zip(param_keys, fname[:-5].split('__')))\n",
    "\n",
    "        param_str = '__'.join(param_dict[x] for x in param_keys[4:])\n",
    "        dname = param_dict['dataset'].split('-')[0]\n",
    "        subject_type = param_dict['dataset'].split('-')[1]\n",
    "        results_dict[subject_type][param_dict['model']][dname][param_str] = json.load(open(os.path.join(root, fname), 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythia-70m company 10\n",
      "pythia-70m country 9\n",
      "pythia-70m verbs 6\n",
      "pythia-160m temporal 7\n",
      "pythia-160m gender 9\n",
      "pythia-410m company 10\n",
      "pythia-410m country 1\n",
      "pythia-410m verbs 3\n",
      "pythia-6.9b verbs 1\n",
      "pythia-6.9b temporal 4\n",
      "pythia-6.9b gender 7\n"
     ]
    }
   ],
   "source": [
    "for mname in model_names:\n",
    "    for d in dnames:\n",
    "        if len(results_dict['true_subject'][mname][d].keys()) > 0:\n",
    "            print(mname, d, len(results_dict['true_subject'][mname][d].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite noedit results for prefix_subject with true_subject\n",
    "if result_dir == 'log_memit_100723':\n",
    "    for m in model_names:\n",
    "        for d in dnames:\n",
    "            for param_str in results_dict['prefix_subject'][m][d].keys():\n",
    "                results_dict['prefix_subject'][m][d][param_str]['noedit'] = results_dict['true_subject'][m][d][param_str]['noedit']\n",
    "\n",
    "for m in model_names:\n",
    "    for d in dnames:\n",
    "        for param_str in results_dict['prefix_subject'][m][d].keys():\n",
    "            assert results_dict['prefix_subject'][m][d][param_str]['noedit']['general_score'] == \\\n",
    "                results_dict['true_subject'][m][d][param_str]['noedit']['general_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether results fall in each league\n",
    "for st in subject_types:\n",
    "    for m in model_names:\n",
    "        for d in dnames:\n",
    "            for param_str in results_dict[st][m][d].keys():\n",
    "                data = results_dict[st][m][d][param_str] \n",
    "\n",
    "                for league in LEAGUES:\n",
    "                    league_loss_cutoff = data['noedit']['general_score']*(1+league)\n",
    "                    data['edit']['in_league_{}'.format(league)] = data['edit']['general_score'] < league_loss_cutoff\n",
    "                data['edit']['intervention_score_delta'] = data['edit']['intervention_score'] - data['noedit']['intervention_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n",
      "[-0.05937500000000007, -0.3125, -0.15312500000000007, -0.08437499999999998, -0.309375, -0.16249999999999998, -0.11562499999999998, -0.125, -0.25625, -0.271875]\n"
     ]
    }
   ],
   "source": [
    "data = results_dict['true_subject']['pythia-6.9b']['gender']\n",
    "param_strs = data.keys()\n",
    "print([data[param_str]['edit']['in_league_1e-05'] for param_str in param_strs])\n",
    "print([data[param_str]['edit']['intervention_score_delta'] for param_str in param_strs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18500000000000005\n"
     ]
    }
   ],
   "source": [
    "print(sum([data[param_str]['edit']['intervention_score_delta'] for param_str in param_strs]) / len(param_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, False, True]\n",
      "[-0.078125, -0.265625, -0.1468750000000001, -0.15625, -0.109375, -0.23750000000000004, -0.26250000000000007]\n"
     ]
    }
   ],
   "source": [
    "data = results_dict['true_subject']['pythia-6.9b']['gender']\n",
    "param_strs = data.keys()\n",
    "print([data[param_str]['edit']['in_league_1e-05'] for param_str in param_strs])\n",
    "print([data[param_str]['edit']['intervention_score_delta'] for param_str in param_strs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17946428571428572\n"
     ]
    }
   ],
   "source": [
    "print(sum([data[param_str]['edit']['intervention_score_delta'] for param_str in param_strs]) / len(param_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best_config for each league\n",
    "best_configs = {}\n",
    "for m in model_names:\n",
    "    best_configs[m] = {}\n",
    "    for d in dnames:\n",
    "        for st in subject_types:\n",
    "            full_dname = '{}-{}'.format(d, st)\n",
    "            best_configs[m][full_dname] = {}\n",
    "best_results = {}\n",
    "for st in subject_types:\n",
    "    best_results[st] = {}\n",
    "    for m in model_names:\n",
    "        best_results[st][m] = {}\n",
    "        for d in dnames:\n",
    "            best_results[st][m][d] = {}\n",
    "\n",
    "for st in subject_types:\n",
    "    for m in model_names:\n",
    "        for d in dnames:\n",
    "            full_dname = '{}-{}'.format(d, st)\n",
    "            for league in LEAGUES:\n",
    "                # find the best config for each league\n",
    "\n",
    "                # find the runs in each league\n",
    "                options = []\n",
    "                for param_str in results_dict[st][m][d].keys():\n",
    "                    data = results_dict[st][m][d][param_str] \n",
    "                    if data['edit']['in_league_{}'.format(league)]:\n",
    "                        options.append(data)\n",
    "                # find the best run\n",
    "                lowest_intervention_score_delta = float('inf')\n",
    "                best_config = None \n",
    "                best_data = None\n",
    "                for data in options:\n",
    "                    if data['edit']['intervention_score_delta'] < lowest_intervention_score_delta:\n",
    "                        lowest_intervention_score_delta = data['edit']['intervention_score_delta']\n",
    "                        best_config = data['edit']['override_params']\n",
    "                        best_data = data\n",
    "\n",
    "                best_configs[m][full_dname][league] = best_config\n",
    "                best_results[st][m][d][league] = best_data\n",
    "\n",
    "                # # print\n",
    "                score_deltas = [data['edit']['intervention_score_delta'] for data in options]\n",
    "                if len(options) == 0:\n",
    "                #     print(\"NO OPTIONS\")\n",
    "                    continue \n",
    "                best_index = score_deltas.index(min(score_deltas))\n",
    "\n",
    "                scores = [data['edit']['intervention_score'] for data in options]\n",
    "                best_score_index = scores.index(min(scores))\n",
    "                assert best_score_index == best_index\n",
    "\n",
    "                # print('score_deltas:', score_deltas)\n",
    "                # print('best_index:', best_index)\n",
    "                # print('best_score:', score_deltas[best_index])\n",
    "\n",
    "                # print('chosen config:', options[best_index])\n",
    "                # print('chosen config:', best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results.keys()\n",
    "best_results['oracle'] = best_results['true_subject']\n",
    "best_results['prefix'] = best_results['prefix_subject']\n",
    "del best_results['true_subject']\n",
    "del best_results['prefix_subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4615780485332017, 2.461709047727175)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = list(results_dict[st][mname][dname].values())[0]\n",
    "# data['noedit']['general_score'] * (1 + 1e-5), data['edit']['general_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'intervention_score': 0.746875,\n",
       "  'general_score': 2.461709047727175,\n",
       "  'rest_of_prompt_score': 4.320410564791771,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.07196986295533628,\n",
       "   'mom2_update_weight': 67872,\n",
       "   'kl_factor': 0.05166268048920571},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.05937500000000007},\n",
       " {'intervention_score': 0.49375,\n",
       "  'general_score': 2.461786432376122,\n",
       "  'rest_of_prompt_score': 4.330335831180696,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.3657366293916082,\n",
       "   'mom2_update_weight': 31443,\n",
       "   'kl_factor': 0.05548350519905669},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': True,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.3125},\n",
       " {'intervention_score': 0.653125,\n",
       "  'general_score': 2.4619917738033847,\n",
       "  'rest_of_prompt_score': 4.340276115171371,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.1606518378829931,\n",
       "   'mom2_update_weight': 70141,\n",
       "   'kl_factor': 0.014489644151607108},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.15312500000000007},\n",
       " {'intervention_score': 0.721875,\n",
       "  'general_score': 2.461964542277924,\n",
       "  'rest_of_prompt_score': 4.32573243171938,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.053378396260240116,\n",
       "   'mom2_update_weight': 17699,\n",
       "   'kl_factor': 0.040453137697182236},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.08437499999999998},\n",
       " {'intervention_score': 0.496875,\n",
       "  'general_score': 2.462175997737173,\n",
       "  'rest_of_prompt_score': 4.3238520468434976,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.2850050359463888,\n",
       "   'mom2_update_weight': 25502,\n",
       "   'kl_factor': 0.055353460422046676},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.309375},\n",
       " {'intervention_score': 0.64375,\n",
       "  'general_score': 2.462067667579457,\n",
       "  'rest_of_prompt_score': 4.326710047568044,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.1040558278141125,\n",
       "   'mom2_update_weight': 66465,\n",
       "   'kl_factor': 0.017674030522754885},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.16249999999999998},\n",
       " {'intervention_score': 0.690625,\n",
       "  'general_score': 2.462048666078917,\n",
       "  'rest_of_prompt_score': 4.338374919276084,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.10724643357820046,\n",
       "   'mom2_update_weight': 50841,\n",
       "   'kl_factor': 0.05313765575910803},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.11562499999999998},\n",
       " {'intervention_score': 0.68125,\n",
       "  'general_score': 2.461883595926331,\n",
       "  'rest_of_prompt_score': 4.320744067776587,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.12236287486716506,\n",
       "   'mom2_update_weight': 71341,\n",
       "   'kl_factor': 0.03205034771645751},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.125},\n",
       " {'intervention_score': 0.55,\n",
       "  'general_score': 2.4618682401555314,\n",
       "  'rest_of_prompt_score': 4.323048036636845,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.23972648900449214,\n",
       "   'mom2_update_weight': 30876,\n",
       "   'kl_factor': 0.05672266946711038},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.25625},\n",
       " {'intervention_score': 0.534375,\n",
       "  'general_score': 2.4618026624581466,\n",
       "  'rest_of_prompt_score': 4.332720888199344,\n",
       "  'hard_negative_score': None,\n",
       "  'override_params': {'layers': None,\n",
       "   'v_num_grad_steps': 20,\n",
       "   'clamp_norm_factor': 0.21581458404365803,\n",
       "   'mom2_update_weight': 69788,\n",
       "   'kl_factor': 0.03596454005817598},\n",
       "  'in_league_0.001': True,\n",
       "  'in_league_0.0001': False,\n",
       "  'in_league_1e-05': False,\n",
       "  'intervention_score_delta': -0.271875}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_results['prefix']['pythia-6.9b']['country'][1e-5]\n",
    "st = 'true_subject'\n",
    "mname = 'pythia-6.9b'\n",
    "dname = 'gender'\n",
    "[x['edit'] for x in results_dict[st][mname][dname].values()]\n",
    "# [x['edit']['in_league_1e-05'] for x in results_dict[st][mname][dname].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_results.val.final.json\", \"w\") as fh:\n",
    "    json.dump(best_results, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make test scripts (using best val config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_test_scripts = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 5\n",
    "out_log_dir = 'log_memit_100723_test_results'\n",
    "sweep_script_dir = 'sbatches_100723'\n",
    "sweep_script_write_dir = 'sbatches_100723/test_scripts'\n",
    "\n",
    "from make_sweep import get_sbatch_header, model_name_to_short, model_name_to_full\n",
    "# model_to_queue, model_to_jags\n",
    "\n",
    "\n",
    "def model_to_queue(model_name):\n",
    "    if '410m' in model_name or '160m' in model_name or '70m' in model_name or 'backpack' in model_name:\n",
    "        return 'jag-standard'\n",
    "    else:\n",
    "        return 'jag-lo'\n",
    "    \n",
    "def model_to_jags(model_name):\n",
    "    # if '6.9b' in model_name or '2.8b' in model_name or '1b' in model_name or 'gpt-j' in model_name or '160m' in model_name:\n",
    "    #     return ['jagupard37', 'jagupard38', 'jagupard39']\n",
    "    # elif '1.4b' in model_name:\n",
    "    #     return ['jagupard32', 'jagupard33', 'jagupard34', 'jagupard35', 'jagupard36']\n",
    "    # elif '410m' in model_name:\n",
    "    #     return ['jagupard30', 'jagupard31', ]\n",
    "    # elif '70m' in model_name or 'backpack' in model_name:\n",
    "    #     return ['jagupard28', 'jagupard29', ]\n",
    "    # else:\n",
    "    #     raise ValueError\n",
    "    if '6.9b' in model_name or '2.8b' in model_name or '1.4b' in model_name or '1b' in model_name \\\n",
    "        or 'gpt-j' in model_name:\n",
    "        return ['jagupard37', 'jagupard38', 'jagupard39']\n",
    "    elif '410m' in model_name or '160m' in model_name or '70m' in model_name or 'backpack' in model_name:\n",
    "        return ['jagupard32', 'jagupard33', 'jagupard34', 'jagupard35', 'jagupard36']\n",
    "    else:\n",
    "        raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make scripts for the run on the test data\n",
    "\n",
    "if make_test_scripts:\n",
    "    machine_choosing_index = 0\n",
    "\n",
    "    dname_cfg_map = {\n",
    "        'company': 'company_ceo', 'country': 'country_capital', 'verbs': 'verb_conjugation', \n",
    "        'temporal': 'temporal', 'stereoset': 'stereoset', 'gender': 'pronoun_gender_bias'\n",
    "    }\n",
    "    run_cmds = []\n",
    "    filenames = []\n",
    "    for model_name in best_configs:\n",
    "        for full_dname in best_configs[model_name]:\n",
    "            for league in best_configs[model_name][full_dname]:\n",
    "                cur_config = best_configs[model_name][full_dname][league]\n",
    "                if cur_config is None:\n",
    "                    print(\">> WARNING: NO CONFIG YIELDED FOR\", model_name, full_dname, league)\n",
    "                    continue\n",
    "                dname, subject_type = full_dname.split('-')\n",
    "\n",
    "\n",
    "                short_model_name = model_name_to_short(model_name)\n",
    "                jag_options = model_to_jags(model_name)\n",
    "                nodelist = jag_options[machine_choosing_index % len(jag_options)]\n",
    "                machine_choosing_index += 1 \n",
    "\n",
    "\n",
    "                with open(f\"{sweep_script_write_dir}/{short_model_name}_{full_dname}_{league}.sbatch\", \"w\") as fh:\n",
    "                    filenames.append(f\"{sweep_script_write_dir}/{short_model_name}_{full_dname}_{league}.sbatch\")\n",
    "\n",
    "                    print(\n",
    "                        get_sbatch_header(\n",
    "                            run_name=f'{short_model_name}_{dname[:3]}_test-sweep', \n",
    "                            partition=model_to_queue(model_name), \n",
    "                            nodelist=nodelist,\n",
    "                            log_output_dir=f\"{sweep_script_dir}/test_logs\",\n",
    "                            num_hrs=12,\n",
    "                        ),\n",
    "                        file=fh\n",
    "                    )\n",
    "\n",
    "                    for t in range(num_trials):\n",
    "                        test_command = (\n",
    "                            f'python3 run_memit.py \"{model_name_to_full[model_name]}\" --v_num_grad_steps 20 '\n",
    "                            f'--clamp_norm_factor {cur_config[\"clamp_norm_factor\"]} '\n",
    "                            f'--mom2_update_weight {cur_config[\"mom2_update_weight\"]} '\n",
    "                            f'--kl_factor {cur_config[\"kl_factor\"]} '\n",
    "                            f'--dataset_names {dname} '\n",
    "                            f'--subject_types {subject_type} '\n",
    "                            f'--log_dir {out_log_dir} --test_mode '\n",
    "                            f'--override_exp_name {short_model_name}__{full_dname}__{league}__trial{t} '\n",
    "                            f'--seed {t}')\n",
    "\n",
    "                        run_cmd = (\n",
    "                            f\"{test_command} >> {sweep_script_dir}/test_logs/log.{short_model_name}_{full_dname}_{league}_{t}.txt\"\n",
    "                        )\n",
    "                        # run_cmd = (\n",
    "                        #     f\"srun --unbuffered run_as_child_processes '{test_command}' \"\n",
    "                        #     f\">> {sweep_script_dir}/test_logs/log.{model_name}_{full_dname}_{league}_{t}.txt\"\n",
    "                        # )                    \n",
    "                        print(run_cmd, file=fh)\n",
    "                        run_cmds.append(run_cmd)\n",
    "\n",
    "\n",
    "    for x in filenames:\n",
    "        print('sbatch', x)\n",
    "    print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backpacks-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
