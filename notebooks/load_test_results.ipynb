{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'backpack-gpt2',\n",
    "    'pythia-70m',\n",
    "    'pythia-160m',\n",
    "    'pythia-410m',\n",
    "    'pythia-1b',\n",
    "    'pythia-1.4b',\n",
    "    'pythia-2.8b',\n",
    "    'pythia-6.9b'\n",
    "]\n",
    "dnames = [\n",
    "    'company', \n",
    "    'country', \n",
    "    'verbs', \n",
    "    'temporal', \n",
    "    'stereoset', \n",
    "    'gender'    \n",
    "]\n",
    "leagues = [1e-3, 1e-4, 1e-5]\n",
    "subject_types = ['true', 'prefix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = []\n",
    "for root, dirs, files in os.walk(\"sbatches_100723/test_scripts\"):\n",
    "    for fname in files:\n",
    "        if 'noedit' not in fname:\n",
    "            fnames.append(fname)\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = []\n",
    "for fname in fnames:\n",
    "    vals = fname[:-7].split('_')\n",
    "    exps.append(vals[0] + '__' + vals[1] +'_' + vals[2] + '__' + vals[3] )\n",
    "len(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test results\n",
    "results_dir = \"log_memit_100723_test_results\"\n",
    "test_results = defaultdict(list)\n",
    "for root, dirs, files in os.walk(results_dir):\n",
    "    for fname in files:\n",
    "        if 'noedit' in fname:\n",
    "            continue\n",
    "        vals = fname[:-5].split('__')\n",
    "        exp_id = '__'.join(vals[:-1])\n",
    "    \n",
    "        with open(os.path.join(results_dir, fname), 'r') as fh:\n",
    "            data = json.load(fh)\n",
    "            test_results[exp_id].append(data)\n",
    "\n",
    "for k in sorted(test_results.keys()):\n",
    "    if len(test_results[k]) != 5:\n",
    "        print(\"Warning: did not find 5 runs for\", k, len(test_results[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(exps):\n",
    "    assert k in test_results.keys()\n",
    "for k in test_results.keys():\n",
    "    assert k in exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_sweep import model_name_to_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': {'mean': 0.8188888888888888,\n",
       "  'stdv': 0.013310165056345523},\n",
       " 'success_rate_change': {'mean': 0.05611111111111111,\n",
       "  'stdv': 0.013310165056345523,\n",
       "  'full_baseline_intervention': [0.875, 0.875, 0.875, 0.875, 0.875],\n",
       "  'full_intervention_scores': [0.8305555555555556,\n",
       "   0.8305555555555556,\n",
       "   0.7944444444444444,\n",
       "   0.8166666666666667,\n",
       "   0.8222222222222222]},\n",
       " 'hard_negative_score': {'mean': 1.923723404255319,\n",
       "  'stdv': 0.003681935079547429},\n",
       " 'hard_negative_score_change': {'mean': 0.01153922872340427,\n",
       "  'stdv': 0.003681935079547429},\n",
       " 'n': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_results(model_name, league, dname, subject_type, verbose=False):\n",
    "    exp_id = f'{model_name_to_short(model_name)}__{dname}-{subject_type}_subject__{league}'\n",
    "\n",
    "    # get rid of runs that are out-of-league\n",
    "    options = []\n",
    "    for exp_run in test_results[exp_id]:\n",
    "        league_cutoff = exp_run['noedit']['general_score'] * (1+league)\n",
    "        if exp_run['edit']['general_score'] < league_cutoff:\n",
    "            options.append(exp_run)\n",
    "    if verbose:\n",
    "        print(f\"{exp_id} has {len(test_results[exp_id])} entries, of which {len(options)} are in-league\")\n",
    "\n",
    "    general_scores = [exp_run['edit']['general_score'] for exp_run in options]\n",
    "    intervention_scores = [exp_run['edit']['intervention_score'] for exp_run in options]\n",
    "    hard_negative_scores = [exp_run['edit']['hard_negative_score'] for exp_run in options]\n",
    "\n",
    "    baseline_intervention = [exp_run['noedit']['intervention_score'] for exp_run in options]\n",
    "    baseline_hard_negative = [exp_run['noedit']['hard_negative_score'] for exp_run in options]\n",
    "\n",
    "    success_rate_change = np.array(baseline_intervention) - np.array(intervention_scores)\n",
    "    hard_negative_score_change = np.array(hard_negative_scores) - np.array(baseline_hard_negative)\n",
    "    return {\n",
    "        'intervention_score': {\n",
    "            'mean': np.mean(intervention_scores),\n",
    "            'stdv': np.std(intervention_scores),\n",
    "        },\n",
    "        'success_rate_change': {\n",
    "            'mean': np.mean(success_rate_change),\n",
    "            'stdv': np.std(success_rate_change),\n",
    "            'full_baseline_intervention': baseline_intervention,\n",
    "            'full_intervention_scores': intervention_scores,\n",
    "        },\n",
    "        'hard_negative_score': {\n",
    "            'mean': np.mean(hard_negative_scores),\n",
    "            'stdv': np.std(hard_negative_scores),\n",
    "        },\n",
    "        'hard_negative_score_change': {\n",
    "            'mean': np.mean(hard_negative_score_change),\n",
    "            'stdv': np.std(hard_negative_score_change),\n",
    "        },\n",
    "        'n': len(general_scores),\n",
    "    }\n",
    "\n",
    "\n",
    "model_name = 'pythia-1.4b' # 'pythia-410m'\n",
    "league = 1e-3\n",
    "dname = 'gender' # 'country'\n",
    "subject_type = 'prefix'\n",
    "\n",
    "get_test_results(model_name, league, dname, subject_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for subject_type in subject_types:\n",
    "    results[subject_type] = {}\n",
    "    for model_name in model_names:\n",
    "        results[subject_type][model_name] = {}\n",
    "        for dname in dnames:\n",
    "            results[subject_type][model_name][dname] = {}\n",
    "            for league in leagues:\n",
    "                results[subject_type][model_name][dname][league] = get_test_results(model_name, league, dname, subject_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['oracle'] = results['true']\n",
    "del results['true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': {'mean': 0.5194444444444445,\n",
       "  'stdv': 0.002777777777777768},\n",
       " 'success_rate_change': {'mean': 0.3833333333333333,\n",
       "  'stdv': 0.002777777777777768,\n",
       "  'full_baseline_intervention': [0.9027777777777778, 0.9027777777777778],\n",
       "  'full_intervention_scores': [0.5222222222222223, 0.5166666666666667]},\n",
       " 'hard_negative_score': {'mean': 1.7455535239361701,\n",
       "  'stdv': 0.0005402260638297518},\n",
       " 'hard_negative_score_change': {'mean': 0.02055352393617016,\n",
       "  'stdv': 0.0005402260638297518},\n",
       " 'n': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'pythia-6.9b'\n",
    "dname = 'gender'\n",
    "league = 1e-4\n",
    "results['oracle'][model_name][dname][league]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_results.test.final.json\", \"w\") as fh:\n",
    "    json.dump(results, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prefix', 'oracle'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': {'mean': 0.8188888888888888,\n",
       "  'stdv': 0.013310165056345523},\n",
       " 'success_rate_change': {'mean': 0.05611111111111111,\n",
       "  'stdv': 0.013310165056345523,\n",
       "  'full_baseline_intervention': [0.875, 0.875, 0.875, 0.875, 0.875],\n",
       "  'full_intervention_scores': [0.8305555555555556,\n",
       "   0.8305555555555556,\n",
       "   0.7944444444444444,\n",
       "   0.8166666666666667,\n",
       "   0.8222222222222222]},\n",
       " 'hard_negative_score': {'mean': 1.923723404255319,\n",
       "  'stdv': 0.003681935079547429},\n",
       " 'hard_negative_score_change': {'mean': 0.01153922872340427,\n",
       "  'stdv': 0.003681935079547429},\n",
       " 'n': 5}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['prefix']['pythia-1.4b']['gender'][0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre 10-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise # don't run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['backpack-gpt2', 'pythia-160m', 'pythia-1.4b', 'pythia-6.9b', 'pythia-410m', 'pythia-1b', 'pythia-70m', 'pythia-2.8b'])\n"
     ]
    }
   ],
   "source": [
    "# baseline_scores = {}\n",
    "# for root, dirs, files in os.walk(\"log_memit_100223\"):\n",
    "#     for fname in files:\n",
    "#         if 'noedit' in fname:\n",
    "#             # print(fname)\n",
    "#             model_name = fname.split('__')[0].split('noedit.')[1]\n",
    "#             dataset_name = fname.split('__')[1].split('-')[0]\n",
    "#             data = json.load(open(os.path.join(root, fname), 'r'))\n",
    "            \n",
    "#             if model_name not in baseline_scores:\n",
    "#                 baseline_scores[model_name] = {}\n",
    "\n",
    "#             baseline_scores[model_name][dataset_name] = data\n",
    "# print(baseline_scores.keys())\n",
    "# print(baseline_scores['pythia-6.9b']['gender'])\n",
    "# with open(\"memit_results.noedit.val.v2.json\", \"w\") as fh:\n",
    "#     json.dump(baseline_scores, fh)\n",
    "    \n",
    "baseline_scores = {}\n",
    "for root, dirs, files in os.walk(\"log_memit_100223_test_results\"):\n",
    "    for fname in files:\n",
    "        if 'noedit' in fname:\n",
    "            # print(fname)\n",
    "            model_name = fname.split('__')[0].split('noedit.')[1]\n",
    "            dataset_name = fname.split('__')[1].split('-')[0]\n",
    "            data = json.load(open(os.path.join(root, fname), 'r'))\n",
    "            \n",
    "            if model_name not in baseline_scores:\n",
    "                baseline_scores[model_name] = {}\n",
    "\n",
    "            baseline_scores[model_name][dataset_name] = data\n",
    "print(baseline_scores.keys())\n",
    "\n",
    "with open(\"memit_results.noedit.test.v4.json\", \"w\") as fh:\n",
    "    json.dump(baseline_scores, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = 'pythia-70m' #  'pythia-6.9b' # \n",
    "dname = 'country' # 'company' # 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': 0.9965694682675815,\n",
       " 'general_score': 5.6242944101325145,\n",
       " 'rest_of_prompt_score': 6.127375163172184,\n",
       " 'hard_negative_score': 20.467924446895204}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores[mname][dname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': 0.9965694682675815,\n",
       " 'general_score': 5.6242944101325145,\n",
       " 'rest_of_prompt_score': 6.127375163172184,\n",
       " 'hard_negative_score': 20.467924446895204}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"memit_results.noedit.test.v3.withWrap.json\", \"r\") as fh:\n",
    "    results_read = json.load(fh)\n",
    "results_read[mname][dname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': 0.08611111111111111,\n",
       " 'general_score': 5.328501239480092,\n",
       " 'rest_of_prompt_score': 7.299414927261227,\n",
       " 'hard_negative_score': 4.0950797872340425}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"memit_results.noedit.test.v2.json\", \"r\") as fh:\n",
    "    results_read = json.load(fh)\n",
    "results_read[mname][dname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythia-70m__country-prefix_subject__0.0001 5\n",
      "pythia-2.8b__verbs-true_subject__1e-05 5\n",
      "pythia-2.8b__country-true_subject__0.0001 5\n",
      "pythia-160m__verbs-true_subject__1e-05 5\n",
      "pythia-160m__temporal-prefix_subject__1e-05 5\n",
      "pythia-160m__country-true_subject__0.0001 5\n",
      "pythia-70m__temporal-prefix_subject__1e-05 5\n",
      "pythia-160m__country-prefix_subject__0.0001 5\n",
      "pythia-2.8b__gender-prefix_subject__1e-05 5\n",
      "pythia-410m__company-prefix_subject__1e-05 5\n",
      "pythia-1b__gender-prefix_subject__0.0001 5\n",
      "pythia-70m__temporal-prefix_subject__0.0001 5\n",
      "pythia-1b__verbs-prefix_subject__1e-05 5\n",
      "pythia-2.8b__company-true_subject__0.0001 5\n",
      "pythia-2.8b__verbs-prefix_subject__0.0001 5\n",
      "pythia-160m__company-true_subject__0.0001 5\n",
      "pythia-6.9b__stereoset-prefix_subject__0.0001 5\n",
      "pythia-160m__verbs-prefix_subject__0.0001 5\n",
      "pythia-6.9b__company-prefix_subject__0.0001 5\n",
      "pythia-410m__gender-prefix_subject__1e-05 5\n",
      "pythia-160m__gender-true_subject__0.0001 5\n",
      "pythia-160m__gender-prefix_subject__1e-05 5\n",
      "pythia-1.4b__temporal-true_subject__0.0001 5\n",
      "pythia-2.8b__gender-true_subject__0.001 5\n",
      "pythia-1b__company-true_subject__0.001 5\n",
      "pythia-6.9b__verbs-true_subject__0.0001 5\n",
      "pythia-2.8b__country-true_subject__1e-05 5\n",
      "pythia-2.8b__country-prefix_subject__0.001 5\n",
      "pythia-6.9b__country-prefix_subject__0.001 5\n",
      "pythia-2.8b__company-true_subject__1e-05 5\n",
      "pythia-6.9b__company-true_subject__1e-05 5\n",
      "pythia-6.9b__temporal-true_subject__0.001 5\n",
      "backpack-gpt2__temporal-prefix_subject__0.001 5\n",
      "pythia-1.4b__gender-prefix_subject__1e-05 5\n",
      "pythia-1b__country-prefix_subject__1e-05 5\n",
      "pythia-1.4b__verbs-prefix_subject__0.0001 5\n",
      "pythia-6.9b__country-true_subject__1e-05 5\n",
      "pythia-1.4b__company-prefix_subject__0.001 5\n",
      "pythia-1.4b__company-true_subject__0.0001 5\n",
      "backpack-gpt2__gender-prefix_subject__0.001 5\n",
      "pythia-70m__country-prefix_subject__0.001 5\n",
      "pythia-6.9b__temporal-prefix_subject__0.0001 5\n",
      "pythia-6.9b__verbs-true_subject__1e-05 5\n",
      "pythia-2.8b__verbs-true_subject__0.0001 5\n",
      "pythia-1b__verbs-true_subject__0.001 5\n",
      "pythia-6.9b__gender-true_subject__0.001 5\n",
      "pythia-1.4b__country-true_subject__1e-05 5\n",
      "pythia-1b__gender-prefix_subject__0.001 5\n",
      "pythia-2.8b__company-prefix_subject__0.001 5\n",
      "backpack-gpt2__verbs-prefix_subject__0.001 5\n",
      "backpack-gpt2__gender-true_subject__0.001 5\n",
      "pythia-410m__verbs-true_subject__1e-05 5\n",
      "backpack-gpt2__stereoset-true_subject__0.0001 5\n",
      "pythia-6.9b__company-prefix_subject__0.001 5\n",
      "pythia-70m__verbs-prefix_subject__0.001 5\n",
      "pythia-2.8b__temporal-true_subject__0.001 5\n",
      "pythia-70m__company-prefix_subject__0.001 5\n",
      "pythia-1b__gender-true_subject__0.0001 5\n",
      "pythia-1b__verbs-true_subject__0.0001 5\n",
      "pythia-410m__gender-prefix_subject__0.0001 5\n",
      "pythia-1b__company-prefix_subject__1e-05 5\n",
      "pythia-6.9b__temporal-prefix_subject__0.001 5\n",
      "pythia-410m__verbs-prefix_subject__0.001 5\n",
      "pythia-1.4b__country-prefix_subject__0.001 5\n",
      "pythia-160m__temporal-true_subject__0.001 5\n",
      "pythia-160m__stereoset-prefix_subject__0.001 5\n",
      "pythia-70m__gender-prefix_subject__0.001 5\n",
      "pythia-6.9b__country-true_subject__0.0001 5\n",
      "pythia-160m__country-true_subject__0.001 5\n",
      "pythia-410m__company-true_subject__1e-05 5\n",
      "pythia-160m__company-true_subject__0.001 5\n",
      "pythia-1.4b__gender-true_subject__0.001 5\n",
      "backpack-gpt2__company-true_subject__1e-05 5\n",
      "pythia-1.4b__country-prefix_subject__0.0001 5\n",
      "pythia-70m__verbs-true_subject__1e-05 5\n",
      "backpack-gpt2__company-prefix_subject__0.0001 5\n",
      "backpack-gpt2__verbs-true_subject__0.001 5\n",
      "pythia-6.9b__company-true_subject__0.0001 5\n",
      "backpack-gpt2__temporal-true_subject__1e-05 5\n",
      "pythia-1.4b__verbs-prefix_subject__0.001 5\n",
      "pythia-1.4b__temporal-prefix_subject__0.0001 5\n",
      "pythia-6.9b__verbs-prefix_subject__0.0001 5\n",
      "pythia-70m__temporal-true_subject__0.0001 5\n",
      "pythia-1.4b__temporal-prefix_subject__1e-05 5\n",
      "pythia-410m__gender-true_subject__1e-05 5\n",
      "pythia-1.4b__country-true_subject__0.0001 5\n",
      "pythia-70m__temporal-true_subject__1e-05 5\n",
      "pythia-160m__temporal-true_subject__0.0001 5\n",
      "pythia-1b__country-true_subject__0.001 5\n",
      "pythia-70m__stereoset-prefix_subject__0.0001 5\n",
      "pythia-6.9b__stereoset-true_subject__0.0001 5\n",
      "pythia-1b__country-prefix_subject__0.0001 5\n",
      "backpack-gpt2__temporal-true_subject__0.0001 5\n",
      "pythia-410m__country-prefix_subject__0.0001 5\n",
      "pythia-6.9b__stereoset-prefix_subject__1e-05 5\n",
      "pythia-410m__stereoset-prefix_subject__0.001 5\n",
      "pythia-1.4b__verbs-true_subject__0.001 5\n",
      "pythia-6.9b__verbs-prefix_subject__0.001 5\n",
      "backpack-gpt2__company-prefix_subject__0.001 5\n",
      "pythia-410m__country-true_subject__0.0001 5\n",
      "pythia-160m__company-prefix_subject__0.001 5\n",
      "pythia-1b__stereoset-true_subject__0.001 5\n",
      "pythia-1b__stereoset-prefix_subject__0.001 5\n",
      "pythia-2.8b__verbs-prefix_subject__0.001 5\n",
      "pythia-410m__verbs-prefix_subject__0.0001 5\n",
      "pythia-410m__company-true_subject__0.0001 5\n",
      "pythia-2.8b__country-prefix_subject__0.0001 5\n",
      "pythia-160m__country-prefix_subject__0.001 5\n",
      "pythia-6.9b__temporal-true_subject__0.0001 5\n",
      "pythia-2.8b__temporal-prefix_subject__1e-05 5\n",
      "pythia-2.8b__temporal-true_subject__0.0001 5\n",
      "backpack-gpt2__country-prefix_subject__0.001 5\n",
      "pythia-1.4b__verbs-true_subject__0.0001 5\n",
      "backpack-gpt2__country-true_subject__1e-05 5\n",
      "pythia-70m__gender-true_subject__1e-05 5\n",
      "pythia-1.4b__temporal-true_subject__0.001 5\n",
      "pythia-6.9b__gender-prefix_subject__1e-05 5\n",
      "pythia-70m__country-true_subject__1e-05 5\n",
      "pythia-2.8b__temporal-prefix_subject__0.0001 5\n",
      "pythia-1.4b__company-true_subject__1e-05 5\n",
      "backpack-gpt2__temporal-prefix_subject__0.0001 5\n",
      "pythia-1b__gender-true_subject__0.001 5\n",
      "pythia-1b__stereoset-prefix_subject__0.0001 5\n",
      "pythia-160m__gender-true_subject__1e-05 5\n",
      "pythia-410m__temporal-true_subject__0.001 5\n",
      "pythia-160m__verbs-prefix_subject__1e-05 5\n",
      "backpack-gpt2__verbs-true_subject__0.0001 5\n",
      "pythia-410m__stereoset-true_subject__0.001 5\n",
      "pythia-1b__company-prefix_subject__0.001 5\n",
      "pythia-6.9b__temporal-prefix_subject__1e-05 5\n",
      "pythia-410m__verbs-prefix_subject__1e-05 5\n",
      "backpack-gpt2__stereoset-prefix_subject__0.001 5\n",
      "pythia-160m__temporal-true_subject__1e-05 5\n",
      "pythia-1.4b__country-prefix_subject__1e-05 5\n",
      "pythia-2.8b__gender-true_subject__0.0001 5\n",
      "pythia-1b__stereoset-true_subject__0.0001 5\n",
      "pythia-6.9b__country-prefix_subject__0.0001 5\n",
      "pythia-2.8b__temporal-true_subject__1e-05 5\n",
      "pythia-410m__stereoset-true_subject__0.0001 5\n",
      "pythia-1b__country-true_subject__0.0001 5\n",
      "pythia-70m__verbs-prefix_subject__1e-05 5\n",
      "backpack-gpt2__stereoset-true_subject__0.001 5\n",
      "pythia-160m__verbs-true_subject__0.0001 5\n",
      "pythia-6.9b__gender-true_subject__0.0001 5\n",
      "pythia-1.4b__country-true_subject__0.001 5\n",
      "pythia-1b__gender-prefix_subject__1e-05 5\n",
      "pythia-2.8b__company-prefix_subject__1e-05 5\n",
      "backpack-gpt2__verbs-prefix_subject__1e-05 5\n",
      "pythia-160m__stereoset-true_subject__0.001 5\n",
      "pythia-1b__company-true_subject__0.0001 5\n",
      "backpack-gpt2__gender-true_subject__1e-05 5\n",
      "pythia-410m__verbs-true_subject__0.001 5\n",
      "pythia-160m__company-prefix_subject__0.0001 5\n",
      "pythia-1b__verbs-prefix_subject__0.0001 5\n",
      "pythia-6.9b__company-prefix_subject__1e-05 5\n",
      "pythia-70m__company-true_subject__0.001 5\n",
      "pythia-410m__country-prefix_subject__0.001 5\n",
      "pythia-1.4b__temporal-prefix_subject__0.001 5\n",
      "pythia-410m__gender-true_subject__0.001 5\n",
      "pythia-1.4b__gender-prefix_subject__0.0001 5\n",
      "pythia-70m__stereoset-true_subject__0.0001 5\n",
      "pythia-70m__country-true_subject__0.0001 5\n",
      "backpack-gpt2__company-true_subject__0.001 5\n",
      "pythia-70m__verbs-true_subject__0.001 5\n",
      "pythia-160m__temporal-prefix_subject__0.0001 5\n",
      "pythia-1b__temporal-true_subject__0.0001 5\n",
      "backpack-gpt2__verbs-true_subject__1e-05 5\n",
      "pythia-1.4b__verbs-prefix_subject__1e-05 5\n",
      "backpack-gpt2__temporal-true_subject__0.001 5\n",
      "pythia-160m__country-true_subject__1e-05 5\n",
      "pythia-70m__verbs-true_subject__0.0001 5\n",
      "pythia-2.8b__stereoset-prefix_subject__0.001 5\n",
      "pythia-410m__company-true_subject__0.001 5\n",
      "pythia-160m__company-true_subject__1e-05 5\n",
      "pythia-1.4b__gender-true_subject__1e-05 5\n",
      "pythia-70m__gender-prefix_subject__1e-05 5\n",
      "pythia-1.4b__stereoset-prefix_subject__0.001 5\n",
      "pythia-410m__verbs-true_subject__0.0001 5\n",
      "pythia-1b__company-prefix_subject__0.0001 5\n",
      "pythia-2.8b__stereoset-true_subject__0.0001 5\n",
      "pythia-70m__gender-prefix_subject__0.0001 5\n",
      "pythia-410m__gender-prefix_subject__0.001 5\n",
      "pythia-160m__gender-prefix_subject__0.001 5\n",
      "pythia-2.8b__gender-prefix_subject__0.001 5\n",
      "pythia-410m__company-prefix_subject__0.001 5\n",
      "pythia-1b__verbs-prefix_subject__0.001 5\n",
      "pythia-2.8b__stereoset-true_subject__0.001 5\n",
      "pythia-70m__temporal-prefix_subject__0.001 5\n",
      "pythia-6.9b__stereoset-true_subject__0.001 5\n",
      "pythia-1b__temporal-prefix_subject__0.0001 5\n",
      "pythia-1b__temporal-true_subject__0.001 5\n",
      "pythia-2.8b__verbs-true_subject__0.001 5\n",
      "pythia-160m__verbs-true_subject__0.001 5\n",
      "pythia-160m__temporal-prefix_subject__0.001 5\n",
      "pythia-70m__country-prefix_subject__1e-05 5\n",
      "pythia-410m__temporal-true_subject__0.0001 5\n",
      "pythia-1.4b__company-prefix_subject__0.0001 5\n",
      "pythia-6.9b__verbs-true_subject__0.001 5\n",
      "backpack-gpt2__country-prefix_subject__0.0001 5\n",
      "pythia-1b__verbs-true_subject__1e-05 5\n",
      "pythia-6.9b__gender-true_subject__1e-05 5\n",
      "pythia-6.9b__company-true_subject__0.001 5\n",
      "pythia-6.9b__temporal-true_subject__1e-05 5\n",
      "backpack-gpt2__temporal-prefix_subject__1e-05 5\n",
      "pythia-1.4b__gender-prefix_subject__0.001 5\n",
      "pythia-1b__country-prefix_subject__0.001 5\n",
      "pythia-1.4b__gender-true_subject__0.0001 5\n",
      "pythia-6.9b__country-true_subject__0.001 5\n",
      "pythia-1.4b__company-prefix_subject__1e-05 5\n",
      "backpack-gpt2__gender-prefix_subject__1e-05 5\n",
      "pythia-2.8b__country-true_subject__0.001 5\n",
      "pythia-2.8b__country-prefix_subject__1e-05 5\n",
      "pythia-6.9b__country-prefix_subject__1e-05 5\n",
      "pythia-2.8b__company-true_subject__0.001 5\n",
      "pythia-2.8b__gender-true_subject__1e-05 5\n",
      "pythia-1b__company-true_subject__1e-05 5\n",
      "pythia-410m__temporal-prefix_subject__0.0001 5\n",
      "pythia-1.4b__stereoset-true_subject__0.001 5\n",
      "pythia-70m__country-true_subject__0.001 5\n",
      "pythia-410m__stereoset-prefix_subject__0.0001 5\n",
      "backpack-gpt2__country-true_subject__0.001 5\n",
      "pythia-160m__stereoset-true_subject__0.0001 5\n",
      "pythia-70m__gender-true_subject__0.001 5\n",
      "pythia-1.4b__temporal-true_subject__1e-05 5\n",
      "pythia-6.9b__gender-prefix_subject__0.001 5\n",
      "pythia-2.8b__temporal-prefix_subject__0.001 5\n",
      "backpack-gpt2__country-prefix_subject__1e-05 5\n",
      "pythia-410m__country-true_subject__0.001 5\n",
      "pythia-160m__country-prefix_subject__1e-05 5\n",
      "pythia-70m__verbs-prefix_subject__0.0001 5\n",
      "pythia-410m__company-prefix_subject__0.0001 5\n",
      "pythia-160m__verbs-prefix_subject__0.001 5\n",
      "pythia-160m__gender-true_subject__0.001 5\n",
      "backpack-gpt2__stereoset-prefix_subject__0.0001 5\n",
      "pythia-1.4b__stereoset-prefix_subject__0.0001 5\n",
      "pythia-410m__company-true_subject__na__20__0.9246225157800635__20928 1\n",
      "pythia-1b__gender-true_subject__1e-05 5\n",
      "backpack-gpt2__gender-prefix_subject__0.0001 5\n",
      "pythia-1.4b__company-true_subject__0.001 5\n",
      "pythia-160m__gender-prefix_subject__0.0001 5\n",
      "pythia-160m__stereoset-prefix_subject__0.0001 5\n",
      "pythia-1.4b__verbs-true_subject__1e-05 5\n",
      "backpack-gpt2__company-true_subject__0.0001 5\n",
      "pythia-2.8b__stereoset-prefix_subject__0.0001 5\n",
      "backpack-gpt2__verbs-prefix_subject__0.0001 5\n",
      "pythia-2.8b__company-prefix_subject__0.0001 5\n",
      "pythia-6.9b__stereoset-prefix_subject__0.001 5\n",
      "pythia-1b__temporal-prefix_subject__0.001 5\n",
      "pythia-70m__temporal-true_subject__0.001 5\n",
      "backpack-gpt2__country-true_subject__0.0001 5\n",
      "pythia-1b__country-true_subject__1e-05 5\n",
      "pythia-410m__temporal-prefix_subject__0.001 5\n",
      "pythia-2.8b__verbs-prefix_subject__1e-05 5\n",
      "pythia-410m__gender-true_subject__0.0001 5\n",
      "pythia-70m__stereoset-true_subject__0.001 5\n",
      "pythia-6.9b__gender-prefix_subject__0.0001 5\n",
      "pythia-1.4b__stereoset-true_subject__0.0001 5\n",
      "pythia-2.8b__gender-prefix_subject__0.0001 5\n",
      "pythia-70m__gender-true_subject__0.0001 5\n",
      "pythia-160m__company-prefix_subject__1e-05 5\n",
      "pythia-70m__stereoset-prefix_subject__0.001 5\n",
      "backpack-gpt2__company-prefix_subject__1e-05 5\n",
      "pythia-6.9b__verbs-prefix_subject__1e-05 5\n",
      "backpack-gpt2__gender-true_subject__0.0001 5\n",
      "pythia-410m__company-true_subject 1\n"
     ]
    }
   ],
   "source": [
    "# load test results\n",
    "test_results = defaultdict(list)\n",
    "for root, dirs, files in os.walk(\"log_memit_100223_test_results\"):\n",
    "    for fname in files:\n",
    "        if 'noedit' in fname:\n",
    "            continue\n",
    "        vals = fname[:-5].split('__')\n",
    "        exp_id = '__'.join(vals[:-1])\n",
    "    \n",
    "        with open(os.path.join(\"log_memit_100223_test_results\", fname), 'r') as fh:\n",
    "            data = json.load(fh)\n",
    "            test_results[exp_id].append(data)\n",
    "\n",
    "for k in test_results:\n",
    "    print(k, len(test_results[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_results(model_name, league, dname, subject_type, return_dicts=False):\n",
    "    exp_id = f'{model_name}__{dname}-{subject_type}_subject__{league}'\n",
    "    league_cutoff = baseline_scores[model_name][dname]['general_score'] * (1+league)\n",
    "\n",
    "    # print(\"exp_id\", exp_id)\n",
    "    # print(\"league_cutoff\", league_cutoff)\n",
    "\n",
    "    general_scores = np.array([x['general_score'] for x in test_results[exp_id]])\n",
    "    intervention_scores = np.array([x['intervention_score'] for x in test_results[exp_id]])\n",
    "    hard_negative_scores = np.array([x['hard_negative_score'] for x in test_results[exp_id]])\n",
    "\n",
    "    # print(general_scores.shape, intervention_scores.shape)\n",
    "\n",
    "    # get rid of invalid entries\n",
    "    indexer = general_scores < league_cutoff\n",
    "    general_scores = general_scores[indexer]\n",
    "    intervention_scores = intervention_scores[indexer]\n",
    "    hard_negative_scores = hard_negative_scores[indexer]\n",
    "    assert ((np.array(general_scores) < league_cutoff).all())\n",
    "\n",
    "    baseline_intervention = baseline_scores[model_name][dname]['intervention_score'] * (1+league)\n",
    "    baseline_hard_negative = baseline_scores[model_name][dname]['hard_negative_score']\n",
    "    # print(\"baseline_intervention\", baseline_intervention)\n",
    "    \n",
    "    # print(np.var(intervention_scores))\n",
    "    \n",
    "    # print(np.var(hard_negative_scores))\n",
    "\n",
    "\n",
    "    # print('success delta:', baseline_intervention - np.mean(intervention_scores) )\n",
    "    # print('hard negative score:', np.mean(hard_negative_scores))\n",
    "\n",
    "    if return_dicts:\n",
    "        return {\n",
    "            'intervention_score': {\n",
    "                'mean': np.mean(intervention_scores),\n",
    "                'stdv': np.std(intervention_scores),\n",
    "            },\n",
    "            'success_rate_change': {\n",
    "                'mean': baseline_intervention - np.mean(intervention_scores),\n",
    "                'stdv': np.std(intervention_scores),\n",
    "            },\n",
    "            'hard_negative_score': {\n",
    "                'mean': np.mean(hard_negative_scores),\n",
    "                'stdv': np.std(hard_negative_scores),\n",
    "            },\n",
    "            'n': len(general_scores),\n",
    "        }\n",
    "    return baseline_intervention - np.mean(intervention_scores), np.mean(hard_negative_scores)\n",
    "\n",
    "# model_name = 'pythia-1.4b' # 'pythia-410m'\n",
    "# league = 1e-3\n",
    "# dname = 'gender' # 'country'\n",
    "# subject_type = 'prefix'\n",
    "\n",
    "# get_test_results(model_name, league, dname, subject_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/nlp/scr/sachen/miniconda3/envs/backpacks-env/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print_table = False \n",
    "results = {}\n",
    "hard_negs = {}\n",
    "for subject_type in subject_types:\n",
    "    results[subject_type] = {}\n",
    "    if print_table:\n",
    "        print('='*40)\n",
    "        print(subject_type, 'subject')\n",
    "    for model_name in model_names:\n",
    "        results[subject_type][model_name] = {}\n",
    "        if print_table:\n",
    "            print('\\n')\n",
    "            print(\"model_name\", model_name)\n",
    "        for dname in dnames:\n",
    "            results[subject_type][model_name][dname] = {}\n",
    "            for league in leagues:\n",
    "                results[subject_type][model_name][dname][league] = get_test_results(model_name, league, dname, subject_type, return_dicts=True)\n",
    "                # print(f\"{model_name}__{dname}-{s_type}__{league}\")\n",
    "\n",
    "            # if print_table:\n",
    "            # print(dname, *success_deltas[model_name], sep='\\t')\n",
    "            # print(dname, *hard_negs[model_name], sep='\\t')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': {0.001: {'intervention_score': {'mean': 1.0, 'stdv': 0.0},\n",
       "   'success_rate_change': {'mean': 0.0009999999999998899, 'stdv': 0.0},\n",
       "   'hard_negative_score': {'mean': 24.573002810891904,\n",
       "    'stdv': 0.0017726167701983344},\n",
       "   'n': 5},\n",
       "  0.0001: {'intervention_score': {'mean': nan, 'stdv': nan},\n",
       "   'success_rate_change': {'mean': nan, 'stdv': nan},\n",
       "   'hard_negative_score': {'mean': nan, 'stdv': nan},\n",
       "   'n': 0},\n",
       "  1e-05: {'intervention_score': {'mean': nan, 'stdv': nan},\n",
       "   'success_rate_change': {'mean': nan, 'stdv': nan},\n",
       "   'hard_negative_score': {'mean': nan, 'stdv': nan},\n",
       "   'n': 0}},\n",
       " 'country': {0.001: {'intervention_score': {'mean': 0.9965694682675815,\n",
       "    'stdv': 0.0},\n",
       "   'success_rate_change': {'mean': 0.00271355060034284, 'stdv': 0.0},\n",
       "   'hard_negative_score': {'mean': 14.523434034298205,\n",
       "    'stdv': 0.004414291341329034},\n",
       "   'n': 5},\n",
       "  0.0001: {'intervention_score': {'mean': 0.9965694682675815, 'stdv': 0.0},\n",
       "   'success_rate_change': {'mean': 0.0018150943396225694, 'stdv': 0.0},\n",
       "   'hard_negative_score': {'mean': 14.523434034298205,\n",
       "    'stdv': 0.004414291341329034},\n",
       "   'n': 5},\n",
       "  1e-05: {'intervention_score': {'mean': 0.9982847341337907, 'stdv': 0.0},\n",
       "   'success_rate_change': {'mean': 9.982847341438728e-06, 'stdv': 0.0},\n",
       "   'hard_negative_score': {'mean': 14.548039606110805,\n",
       "    'stdv': 0.002445811640438293},\n",
       "   'n': 5}},\n",
       " 'verbs': {0.001: {'intervention_score': {'mean': 0.6055555555555555,\n",
       "    'stdv': 0.004648111258522666},\n",
       "   'success_rate_change': {'mean': 0.13685277777777782,\n",
       "    'stdv': 0.004648111258522666},\n",
       "   'hard_negative_score': {'mean': 65.69953828705681,\n",
       "    'stdv': 0.04912764777886457},\n",
       "   'n': 5},\n",
       "  0.0001: {'intervention_score': {'mean': 0.7366666666666667,\n",
       "    'stdv': 0.0020786985482077734},\n",
       "   'success_rate_change': {'mean': 0.005074166666666713,\n",
       "    'stdv': 0.0020786985482077734},\n",
       "   'hard_negative_score': {'mean': 64.74637800004749,\n",
       "    'stdv': 0.005575847436426404},\n",
       "   'n': 5},\n",
       "  1e-05: {'intervention_score': {'mean': 0.7366666666666667,\n",
       "    'stdv': 0.0020786985482077734},\n",
       "   'success_rate_change': {'mean': 0.005007416666666709,\n",
       "    'stdv': 0.0020786985482077734},\n",
       "   'hard_negative_score': {'mean': 64.74637800004749,\n",
       "    'stdv': 0.005575847436426403},\n",
       "   'n': 5}},\n",
       " 'temporal': {0.001: {'intervention_score': {'mean': 0.9053497942386832,\n",
       "    'stdv': 1.1102230246251565e-16},\n",
       "   'success_rate_change': {'mean': 0.000905349794238508,\n",
       "    'stdv': 1.1102230246251565e-16},\n",
       "   'hard_negative_score': {'mean': 11.497394895829395,\n",
       "    'stdv': 0.00013614931220664702},\n",
       "   'n': 5},\n",
       "  0.0001: {'intervention_score': {'mean': 0.9053497942386832,\n",
       "    'stdv': 1.1102230246251565e-16},\n",
       "   'success_rate_change': {'mean': 9.053497942379529e-05,\n",
       "    'stdv': 1.1102230246251565e-16},\n",
       "   'hard_negative_score': {'mean': 11.497394895829393,\n",
       "    'stdv': 0.00013614931220664702},\n",
       "   'n': 5},\n",
       "  1e-05: {'intervention_score': {'mean': 0.9053497942386832,\n",
       "    'stdv': 1.1102230246251565e-16},\n",
       "   'success_rate_change': {'mean': 9.05349794233512e-06,\n",
       "    'stdv': 1.1102230246251565e-16},\n",
       "   'hard_negative_score': {'mean': 11.497394895829395,\n",
       "    'stdv': 0.00013614931220664702},\n",
       "   'n': 5}},\n",
       " 'stereoset': {0.001: {'intervention_score': {'mean': 0.16562203228869893,\n",
       "    'stdv': 0.0009684747414231364},\n",
       "   'success_rate_change': {'mean': 0.017847103513770196,\n",
       "    'stdv': 0.0009684747414231364},\n",
       "   'hard_negative_score': {'mean': 68.38192425299462,\n",
       "    'stdv': 0.09455735445844819},\n",
       "   'n': 5},\n",
       "  0.0001: {'intervention_score': {'mean': 0.17492877492877493,\n",
       "    'stdv': 0.0011074932373875141},\n",
       "   'success_rate_change': {'mean': 0.008375403608736953,\n",
       "    'stdv': 0.0011074932373875141},\n",
       "   'hard_negative_score': {'mean': 66.97156878559225,\n",
       "    'stdv': 0.027545345700035955},\n",
       "   'n': 5},\n",
       "  1e-05: {'intervention_score': {'mean': nan, 'stdv': nan},\n",
       "   'success_rate_change': {'mean': nan, 'stdv': nan},\n",
       "   'hard_negative_score': {'mean': nan, 'stdv': nan},\n",
       "   'n': 0}},\n",
       " 'gender': {0.001: {'intervention_score': {'mean': 0.5266666666666666,\n",
       "    'stdv': 0.036370860674073135},\n",
       "   'success_rate_change': {'mean': 0.42428333333333323,\n",
       "    'stdv': 0.036370860674073135},\n",
       "   'hard_negative_score': {'mean': 2.026565436606712,\n",
       "    'stdv': 0.01247839605675348},\n",
       "   'n': 5},\n",
       "  0.0001: {'intervention_score': {'mean': 0.655, 'stdv': 0.02300026838276052},\n",
       "   'success_rate_change': {'mean': 0.2950949999999999,\n",
       "    'stdv': 0.02300026838276052},\n",
       "   'hard_negative_score': {'mean': 2.080601502935937,\n",
       "    'stdv': 0.010840263848588218},\n",
       "   'n': 5},\n",
       "  1e-05: {'intervention_score': {'mean': 0.8798611111111111,\n",
       "    'stdv': 0.0023032116599690194},\n",
       "   'success_rate_change': {'mean': 0.07014838888888897,\n",
       "    'stdv': 0.0023032116599690194},\n",
       "   'hard_negative_score': {'mean': 2.1652859919882834,\n",
       "    'stdv': 0.0016300996932053077},\n",
       "   'n': 4}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['true']['pythia-70m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': 0.8888888888888888,\n",
       " 'general_score': 2.41024465142832,\n",
       " 'rest_of_prompt_score': 4.991421568627451,\n",
       " 'hard_negative_score': 1.6733304936835107}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores[model_name][dname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': {'mean': 0.9703529411764705,\n",
       "  'stdv': 0.0011527010554274173},\n",
       " 'success_rate_change': {'mean': 0.0015089411764707128,\n",
       "  'stdv': 0.0011527010554274173},\n",
       " 'hard_negative_score': {'mean': 18.16626426836127,\n",
       "  'stdv': 0.0008513854040222031},\n",
       " 'n': 5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['prefix']['backpack-gpt2']['company'][0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_test_results.json\", \"w\") as fh:\n",
    "    json.dump(results, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_test_results.noedit.json\", \"w\") as fh:\n",
    "    json.dump(baseline_scores, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_test_results.json\", \"r\") as fh:\n",
    "    results_read = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memit_test_results.noedit.json\", \"r\") as fh:\n",
    "    results_no_edit = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intervention_score': 0.4638888888888889,\n",
       " 'general_score': 2.41024465142832,\n",
       " 'rest_of_prompt_score': 5.561131437059859,\n",
       " 'hard_negative_score': 47.11877170138889}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_no_edit[model_name][dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/juice4/scr4/sachen/backpack_project/backpack-guarantees/memit/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memit_test_results.json  memit_test_results.noedit.json\n"
     ]
    }
   ],
   "source": [
    "!ls *.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backpacks-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
